{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aeb4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter, FuncFormatter, MultipleLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.ForecastModel.data.models import DataModelCV\n",
    "from src.ForecastModel.utils.losses import loss_peak_mse\n",
    "from src.ForecastModel.utils.metrics import (evaluate_multistep,\n",
    "                                             calculate_rms, calculate_bias, \n",
    "                                             calculate_bias_flv, calculate_bias_fhv,\n",
    "                                            )\n",
    "from src.ForecastModel.utils.postprocessing import ModelHandler\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    'font.size'   : 8,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fa17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt(dates, format=\"%d/%m/%Y %H:%M\"):\n",
    "    if dates.tz == None:\n",
    "        # make TZ aware\n",
    "        return pd.to_datetime(dates, format=format).tz_localize(\"Europe/London\").tz_convert(\"UTC\")\n",
    "    else:\n",
    "        return pd.to_datetime(dates, format=format).tz_convert(\"UTC\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d595bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PATH          = r\"plots\"\n",
    "DATA_PATH          = r\"src\\data\\Dataset.csv\"\n",
    "CROSS_INDICES_PATH = r\"src\\data\\indices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57dc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"arima\": ModelHandler(\"ARIMA\",\n",
    "                r\"src\\rst\\ARIMA\",\n",
    "                is_final_model = True,\n",
    "                is_external_model = True,\n",
    "                color = \"#E69F00\",\n",
    "                ls = \"--\",\n",
    "                  ),\n",
    "    \"arimax\": ModelHandler(\"ARIMAX\",\n",
    "                r\"src\\rst\\ARIMAX\",\n",
    "                is_final_model = True,\n",
    "                is_external_model = True,\n",
    "                color = \"#0072B2\",\n",
    "                ls = \"--\",\n",
    "                  ),\n",
    "     \"pbhm-hlstm\": ModelHandler(\"PBHM-HLSTM\",\n",
    "                   r\"src\\rst\\PBHM-HLSTM\",\n",
    "                   is_final_model = True,\n",
    "                   color = \"#56B4E9\",\n",
    "                   ls = \"-\",\n",
    "                 ),\n",
    "     \"elstm\": ModelHandler(\"eLSTM\",\n",
    "                   r\"src\\rst\\eLSTM\",\n",
    "                   is_final_model = True,\n",
    "                   color = \"#D55E00\",\n",
    "                   ls = \"-\",\n",
    "                 ),\n",
    "     \"lstm\": ModelHandler(\"LSTM\",\n",
    "                   r\"src\\rst\\LSTM\",\n",
    "                   is_final_model = True,\n",
    "                   color = \"#CC79A7\",\n",
    "                   ls = \"-\",\n",
    "                 ),\n",
    "     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd760cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima\n",
      "arimax\n",
      "pbhm-hlstm\n",
      "dictonary loaded\n",
      "35/35 [==============================] - 2s 9ms/step\n",
      "35/35 [==============================] - 1s 8ms/step\n",
      "35/35 [==============================] - 1s 14ms/step\n",
      "35/35 [==============================] - 1s 15ms/step\n",
      "35/35 [==============================] - 1s 16ms/step\n",
      "elstm\n",
      "dictonary loaded\n",
      "35/35 [==============================] - 1s 15ms/step\n",
      "35/35 [==============================] - 1s 7ms/step\n",
      "35/35 [==============================] - 1s 6ms/step\n",
      "35/35 [==============================] - 1s 7ms/step\n",
      "35/35 [==============================] - 1s 11ms/step\n",
      "lstm\n",
      "dictonary loaded\n",
      "35/35 [==============================] - 1s 9ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 8ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# define metrics to evaluate\n",
    "eval_metrics = {\n",
    "        \"pbias\" : calculate_bias,\n",
    "        \"fhv\" : calculate_bias_fhv,\n",
    "        \"flv\" : calculate_bias_flv,\n",
    "    }\n",
    "\n",
    "idx = -10\n",
    "dfp = pd.DataFrame()\n",
    "for n, key in enumerate(models.keys()):\n",
    "    idx += 10\n",
    "    print(key)\n",
    "\n",
    "    metrics = {\n",
    "        \"valid\": {}, \n",
    "        \"test\" : {},\n",
    "    }\n",
    "    for k, item in eval_metrics.items():\n",
    "        metrics[\"test\"][k] = []\n",
    "\n",
    "    eval_path = os.path.join(models[key].hp_path, \"eval_peaks.pckl\")\n",
    "\n",
    "\n",
    "    if models[key].is_external_model:\n",
    "        overlap_length = 0\n",
    "        hindcast_length = 96\n",
    "    else:\n",
    "        # load datamodel\n",
    "        dm = DataModelCV(DATA_PATH,\n",
    "           target_name       = models[key].target_name,\n",
    "           hincast_features  = models[key].feat_hindcast,\n",
    "           forecast_features = models[key].feat_forecast,\n",
    "         )\n",
    "        \n",
    "        # load trial data\n",
    "        with open(os.path.join(models[key].hp_path, \"trial.json\")) as f:\n",
    "            trial = json.load(f)\n",
    "\n",
    "        hindcast_length = trial['hyperparameters']['values']['hindcast_length']\n",
    "        try:\n",
    "            overlap_length = trial['hyperparameters']['values']['osc_length']\n",
    "        except:\n",
    "            overlap_length = 0 \n",
    "        \n",
    "        dm.main(os.path.join(CROSS_INDICES_PATH, f\"cross_indices_{hindcast_length}.pckl\"))\n",
    "\n",
    "    for n_fold in range(5):\n",
    "        year = 2013 + n_fold\n",
    "        if models[key].is_external_model:\n",
    "            # load external which come already with observations\n",
    "            ext_df = pd.read_pickle(os.path.join(models[key].hp_path, f\"forecast_{year}.pckl\"))\n",
    "\n",
    "            # get external model observations\n",
    "            y = np.expand_dims(ext_df.filter(like=\"obs\").values, axis=2) # fix \n",
    "\n",
    "            # get external model predictions\n",
    "            yp = ext_df.filter(like=\"fc\").values\n",
    "                        \n",
    "        else:\n",
    "            # load dataset\n",
    "            X, y  = dm.getDataSet(dm.cross_sets[n_fold][\"test\"], scale=True) \n",
    "\n",
    "            # load model\n",
    "            tf.keras.backend.clear_session()\n",
    "            model  = tf.keras.models.load_model(os.path.join(models[key].hp_path, f\"model_fold_{n_fold:d}.keras\"),\n",
    "                                           custom_objects={'peak_loss'     : loss_peak_mse, # dummy as no costum functions are saved by keras\n",
    "                                                           'kge_nse_loss'  : loss_peak_mse, #\n",
    "                                                           'loss_nkge_nnse': loss_peak_mse, #\n",
    "                                                          })\n",
    "            # model prediction\n",
    "            yp = model.predict(X, batch_size=1000)\n",
    "\n",
    "        for k, item in eval_metrics.items():\n",
    "            metrics[\"test\"][k].append(evaluate_multistep(y, yp, item))\n",
    "\n",
    "    with open(os.path.join(models[key].hp_path, f\"metrics_eval.txt\"), \"w+\") as f:\n",
    "        json.dump(metrics, f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266f6da-e071-4e92-acfe-e435d9a0e6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
