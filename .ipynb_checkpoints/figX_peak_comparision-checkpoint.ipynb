{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aeb4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter, FuncFormatter, MultipleLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from src.ForecastModel.data.models import DataModelCV\n",
    "from src.ForecastModel.utils.metrics import eval_peak_distance, calculate_rms\n",
    "from src.ForecastModel.utils.losses import loss_peak_mse\n",
    "from src.ForecastModel.utils.postprocessing import ModelHandler\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    'font.size'   : 8,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fafc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_n_peaks(df, col_eval, n_peaks, window):\n",
    "    # find the n_peaks most prominent peaks in df[col_eval] and returns peak values with the window\n",
    "    peaks = []\n",
    "    df_length = df.shape[0]\n",
    "    for n_peak in range(n_peaks):\n",
    "        i_max   = df[col_eval].argmax()\n",
    "        i_start = np.max([0, i_max - window//4])\n",
    "        i_end   = np.min([df_length, i_max + window])\n",
    "        \n",
    "        df[\"n_peak\"] = n_peak\n",
    "        peaks.append(df.iloc[i_start:i_end].copy())\n",
    "        \n",
    "        df = df.drop(df.index[i_start:i_end], axis=0)\n",
    "    \n",
    "    peaks = pd.concat(peaks, axis=0)\n",
    "    return peaks\n",
    "\n",
    "def dt(dates, format=\"%d/%m/%Y %H:%M\"):\n",
    "    if dates.tz == None:\n",
    "        # make TZ aware\n",
    "        return pd.to_datetime(dates, format=format).tz_localize(\"Europe/London\").tz_convert(\"UTC\")\n",
    "    else:\n",
    "        return pd.to_datetime(dates, format=format).tz_convert(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423cec6d-c1c0-4c70-bc41-03536417ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PATH          = r\"plots\"\n",
    "DATA_PATH          = r\"src\\data\\Dataset.csv\"\n",
    "CROSS_INDICES_PATH = r\"src\\data\\indices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57dc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {       \n",
    "    \"arima-boxcox\": ModelHandler(\"ARIMA-BOXCOX\",\n",
    "                r\"rst\\ARIMA-BOXCOX\",\n",
    "                is_final_model = True,\n",
    "                is_external_model = True,\n",
    "                color = \"#E69F00\",\n",
    "                ls = \"--\",\n",
    "                  ),\n",
    "    \"arima\": ModelHandler(\"ARIMA\",\n",
    "                r\"rst\\ARIMA\",\n",
    "                is_final_model = True,\n",
    "                is_external_model = True,\n",
    "                color = \"#E69F00\",\n",
    "                ls = \"--\",\n",
    "                  ),\n",
    "\n",
    "    \"arimax\": ModelHandler(\"ARIMAX\",\n",
    "                r\"rst\\ARIMAX\",\n",
    "                is_final_model = True,\n",
    "                is_external_model = True,\n",
    "                color = \"#0072B2\",\n",
    "                ls = \"--\",\n",
    "                  ),\n",
    "\n",
    "     \"pbhm-hlstm\": ModelHandler(\"PBHM-HLSTM\",\n",
    "                   r\"rst\\PBHM-HLSTM\",\n",
    "                   is_final_model = True,\n",
    "                   color = \"#56B4E9\",\n",
    "                   ls = \"-\",\n",
    "                 ),\n",
    "     \"elstm\": ModelHandler(\"eLSTM\",\n",
    "                   r\"rst\\eLSTM\",\n",
    "                   is_final_model = True,\n",
    "                   color = \"#D55E00\",\n",
    "                   ls = \"-\",\n",
    "                 ),\n",
    "     \"lstm\": ModelHandler(\"LSTM\",\n",
    "                   r\"rst\\LSTM\",\n",
    "                   is_final_model = True,\n",
    "                   color = \"#CC79A7\",\n",
    "                   ls = \"-\",\n",
    "                 ),\n",
    "     }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae189f7-535d-4594-b23c-c0d67d5d0ee9",
   "metadata": {},
   "source": [
    "## analyse peak events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef895fcc-a5b4-4a7b-a197-ff7e08959199",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_peaks_per_fold = 2    # number of peaks per fold to analyze\n",
    "load_predictions   = False # load predictions or newly predict with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd760cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima-boxcox\n",
      "extract peaks from model\n",
      "dictonary loaded\n",
      "extracting peaks from fold 0\n",
      "extracting peaks from fold 1\n"
     ]
    }
   ],
   "source": [
    "idx = -10\n",
    "dfp = pd.DataFrame(columns = [\"name\", \"year\", \"peak\", \n",
    "                              \"peak_flow\", \"total_flow\",\n",
    "                              \"hyd_perr\", \"hyd_poff\",\n",
    "                              \"rms_hyd\", \"flow_hyd\", \n",
    "                              \"rms_0\", \"rms_m\", \"rms_95\",\n",
    "                              \"flow_0\", \"flow_m\", \"flow_95\"]\n",
    "                   \n",
    "                        ) \n",
    "dfp = dfp.astype(dtype= {\"name\"     :\"str\",     \"year\"      :\"int32\",    \"peak\"  : \"int32\", \n",
    "                         \"peak_flow\":\"float64\", \"total_flow\":\"float64\",\n",
    "                         \"hyd_perr\" :\"float64\", \"hyd_poff\"  :\"float64\",\n",
    "                         \"rms_hyd\"  :\"float64\", \"flow_hyd\"  :\"float64\", \n",
    "                         \"rms_0\"    :\"float64\", \"rms_m\"     :\"float64\", \"rms_95\" : \"float64\",\n",
    "                         \"flow_0\"   :\"float64\", \"flow_m\"    :\"float64\", \"flow_95\": \"float64\"}\n",
    "                )\n",
    "\n",
    "for n, key in enumerate(models.keys()):\n",
    "    idx += 10\n",
    "    print(key)\n",
    "    fig, axes = plt.subplots(5, num_peaks_per_fold, figsize=(4.72,8), dpi=300)\n",
    "    eval_path = os.path.join(models[key].hp_path, \"eval_peaks.pkl\")\n",
    "    \n",
    "    if (~os.path.exists(eval_path)) | (load_predictions == False):\n",
    "        print(\"extract peaks from model\")\n",
    "        eval_peaks = []\n",
    "\n",
    "        # load datamodel\n",
    "        dm = DataModelCV(DATA_PATH,\n",
    "               target_name       = models[key].target_name,\n",
    "               hincast_features  = models[key].feat_hindcast,\n",
    "               forecast_features = models[key].feat_forecast,\n",
    "             )\n",
    "\n",
    "        if models[key].is_external_model:\n",
    "            overlap_length = 0\n",
    "            hindcast_length = 96\n",
    "        else:\n",
    "            # load trial data\n",
    "            with open(os.path.join(models[key].hp_path, \"trial.json\")) as f:\n",
    "                trial = json.load(f)\n",
    "\n",
    "            hindcast_length = trial['hyperparameters']['values']['hindcast_length']\n",
    "            try:\n",
    "                overlap_length = trial['hyperparameters']['values']['osc_length']\n",
    "            except:\n",
    "                overlap_length = 0 \n",
    "\n",
    "        dm.main(os.path.join(CROSS_INDICES_PATH, f\"cross_indices_{hindcast_length}.pkl\"))\n",
    "\n",
    "        for n_fold in dm.cross_sets.keys():\n",
    "            print(f\"extracting peaks from fold {n_fold}\")\n",
    "            year = 2013 + n_fold\n",
    "\n",
    "            # load dataset\n",
    "            X, y  = dm.getDataSet(dm.cross_sets[n_fold][\"test\"], scale=True) \n",
    "\n",
    "            # get hydrologial model \n",
    "            s = dm.getFeatureSet(n_fold+2, \"qsim\")[2]\n",
    "            df = pd.DataFrame({'index':dt(s.index), 'qhyd':s.values}).set_index(\"index\")\n",
    "\n",
    "            # add ground truth\n",
    "            s = dm.getFeatureSet(n_fold+2, \"qmeasval\")[2]\n",
    "            s.index = dt(s.index)\n",
    "            df = df.merge(s.rename(\"qmeas\").to_frame(), left_index=True, right_index=True)\n",
    "\n",
    "            if models[key].is_external_model:\n",
    "                \n",
    "                ext_df = pd.read_pickle(os.path.join(models[key].hp_path, f\"forecast_{year}.pkl\"))\n",
    "\n",
    "                ext_df.index = pd.date_range(ext_df.index[0], ext_df.index[-1], freq=\"15min\", tz=\"UTC\")\n",
    "                \n",
    "                forecasts_df = ext_df[[f\"fc{x:d}\" for x in range(96)]].copy()\n",
    "                forecasts_df.columns = [f\"q{x:d}\" for x in range(96)]\n",
    "\n",
    "                del ext_df\n",
    "                \n",
    "            else:\n",
    "                # load model\n",
    "                tf.keras.backend.clear_session()\n",
    "                model  = tf.keras.models.load_model(os.path.join(models[key].hp_path, f\"model_fold_{n_fold:d}.keras\"),\n",
    "                                               custom_objects={'peak_loss'    : loss_peak_mse, # dummy as no costum functions are saved by keras\n",
    "                                                              'kge_nse_loss'  : loss_peak_mse, #\n",
    "                                                              'loss_nkge_nnse': loss_peak_mse, #\n",
    "                                                              })\n",
    "\n",
    "                yp = model.predict(X, batch_size=1000)\n",
    "                \n",
    "                if key == \"lstm_residual\":\n",
    "                    _, _, yidx = dm.sets[dm.cross_sets[n_fold][\"test\"]]\n",
    "                    simu = dm.getWithIndexArray([\"qsim\"], yidx)\n",
    "            \n",
    "                    # get real values from residuals\n",
    "                    yp += simu[:,:,0]\n",
    "            \n",
    "                forecasts_df = pd.DataFrame(data    = yp, \n",
    "                                        columns = [f\"q{x:d}\" for x in range(yp.shape[1])],\n",
    "                                        index   = dt(dm.getTimeSet(n_fold+2, 0)[2]))\n",
    "\n",
    "                # save dataframe \n",
    "                df_out = forecasts_df.copy()\n",
    "                df_out.index = pd.to_datetime(df_out.index, format=\"%d/%m/%Y %H:%M\", utc=True)\n",
    "                df_out.to_pickle(os.path.join(models[key].hp_path, f\"forecast_{year}.pkl\"))\n",
    "            \n",
    "            \n",
    "            # get forcasting stats                          \n",
    "            for forecast_step in range(1, forecasts_df.shape[1]):\n",
    "                forecasts_df[f\"q{forecast_step:d}\"] = forecasts_df[f\"q{forecast_step:d}\"].shift(forecast_step)\n",
    "            \n",
    "            # merge model predctions\n",
    "            df = df.merge(forecasts_df, left_index=True, right_index=True)  \n",
    "            \n",
    "            # merge prcipitation\n",
    "            s = pd.Series(dm.getFeatureSet(n_fold+2, \"pmean\", 0)[2].values, dt(dm.getTimeSet(n_fold+2, 0)[2]))\n",
    "            df = df.merge(s.rename(\"pmean\").to_frame(), left_index=True, right_index=True)\n",
    "            \n",
    "            forecasts_df.dropna(inplace=True)\n",
    "            stats_df = pd.DataFrame(columns = [\"fmin\", \"fmax\", \"fmean\", \n",
    "                                               \"fq95\", \"fq90\", \"fq75\",\n",
    "                                               \"fq50\",\n",
    "                                               \"fq25\", \"fq10\", \"fq5\"],\n",
    "                                   index = forecasts_df.index)\n",
    "            \n",
    "            for i, row in forecasts_df.iterrows():\n",
    "                stats_df.loc[i] = [row.values.min(), row.values.max(), row.values.mean()] + \\\n",
    "                                        [np.quantile(row.values, float(x[2:])/100) for x in stats_df.columns[3:]]\n",
    "                  \n",
    "            # merge stats\n",
    "            df = df.merge(stats_df, left_index=True, right_index=True)        \n",
    "            df.dropna(inplace=True)\n",
    "                                           \n",
    "            peaks = get_n_peaks(df, \"qmeas\", num_peaks_per_fold, 24*4)\n",
    "            peaks[\"n_fold\"] = n_fold + 2\n",
    "\n",
    "            # add to summary\n",
    "            eval_peaks.append(peaks)\n",
    "\n",
    "        # save data to pickle\n",
    "        df = pd.concat(eval_peaks, axis=0)\n",
    "        df.to_pickle(eval_path)\n",
    "\n",
    "    df = pd.read_pickle(eval_path)\n",
    "    for n_fold in df.n_fold.unique().tolist():\n",
    "        print(f\"processing fold {n_fold}\")\n",
    "        peaks = df[df.n_fold == n_fold]\n",
    "        for p in range(num_peaks_per_fold):\n",
    "            \n",
    "            dt_index = pd.to_datetime(peaks[peaks.n_peak == p][\"qmeas\"].index, format=\"%d/%m/%Y %H:%M\", utc=True)\n",
    "            timestep = dt_index[1] - dt_index[0]\n",
    "            \n",
    "            axes[n_fold-2, p].grid(\"on\")\n",
    "            \n",
    "            # add precipitation bars\n",
    "            axes[n_fold-2, p].bar(dt_index, \n",
    "                                 - 0.1 * np.cumsum(peaks[peaks.n_peak == p][\"pmean\"].values.astype(np.float64)),\n",
    "                                 timestep, 24,\n",
    "                                 label=\"cum. avg. precipitation\",\n",
    "                                 color= \"b\",\n",
    "                                 alpha = 0.25,\n",
    "                                 )\n",
    "            axes2 = axes[n_fold-2, p].twinx()\n",
    "            axes2.set_yticks(np.arange(240,-1,-40))\n",
    "            axes2.invert_yaxis()\n",
    "\n",
    "            # eval peaks\n",
    "            idx_peak  = peaks[peaks.n_peak == p][\"qmeas\"].argmax()\n",
    "            peak_flow = peaks[peaks.n_peak == p][\"qmeas\"].max()\n",
    "            dfp.loc[idx+n_fold+5*p, [\"hyd_perr\", \"hyd_poff\"]] = [peaks[peaks.n_peak == p][\"qhyd\"].max() - peak_flow,\n",
    "                                                                 peaks[peaks.n_peak == p][\"qhyd\"].argmax() - idx_peak,\n",
    "                                                                ]\n",
    "            dfp.loc[idx+n_fold+5*p, [f\"perr_{x}\" for x in range(96)]] = [peaks[peaks.n_peak == p][f\"q{x}\"].max() - peak_flow for x in range(96)]\n",
    "            dfp.loc[idx+n_fold+5*p, [f\"poff_{x}\" for x in range(96)]] = [peaks[peaks.n_peak == p][f\"q{x}\"].argmax() - idx_peak for x in range(96)]\n",
    "\n",
    "            # eval section\n",
    "            rms_q0 = calculate_rms(peaks[peaks.n_peak == p][\"qmeas\"].values, \n",
    "                                    peaks[peaks.n_peak == p][\"q0\"].values)\n",
    "            rms_qm = calculate_rms(peaks[peaks.n_peak == p][\"qmeas\"].values, \n",
    "                                    peaks[peaks.n_peak == p][\"fmean\"].values)\n",
    "            rms_q95 = calculate_rms(peaks[peaks.n_peak == p][\"qmeas\"].values, \n",
    "                                    peaks[peaks.n_peak == p][\"q95\"].values)\n",
    "            rms_hyd = calculate_rms(peaks[peaks.n_peak == p][\"qmeas\"].values, \n",
    "                                    peaks[peaks.n_peak == p][\"qhyd\"].values)\n",
    "            \n",
    "            peak_flow = peaks[peaks.n_peak == p][\"qmeas\"].max()\n",
    "            \n",
    "            dfp.loc[idx+n_fold+5*p, [\"name\", \"year\", \"peak\"]] = [models[key].name, np.int32(2011+n_fold), np.int32(p)]\n",
    "            dfp.loc[idx+n_fold+5*p, [\"peak_flow\", \"total_flow\"]] = [peak_flow, peaks[peaks.n_peak == p][\"qmeas\"].sum()]\n",
    "            dfp.loc[idx+n_fold+5*p, [\"rms_hyd\", \"flow_hyd\"]] = [rms_hyd,  peaks[peaks.n_peak == p][\"qhyd\"].sum()]\n",
    "            dfp.loc[idx+n_fold+5*p, [\"rms_0\", \"rms_m\", \"rms_95\"]] = [rms_q0, rms_qm, rms_q95]\n",
    "            dfp.loc[idx+n_fold+5*p, [\"flow_0\", \"flow_m\", \"flow_95\"]] = [peaks[peaks.n_peak == p][\"q0\"].sum(),\n",
    "                                                                     peaks[peaks.n_peak == p][\"fmean\"].sum(),\n",
    "                                                                     peaks[peaks.n_peak == p][\"q95\"].sum(),\n",
    "                                                                    ]\n",
    "            \n",
    "            axes[n_fold-2, p].fill_between(peaks[peaks.n_peak == p][\"qmeas\"].index, \n",
    "                                           peaks[peaks.n_peak == p][\"qmeas\"].values,\n",
    "                                           alpha=0.25,\n",
    "                                           color=\"gray\")\n",
    "            \n",
    "            for n in range(5,96,10):\n",
    "                axes[n_fold-2, p].plot(peaks[peaks.n_peak == p][f\"q{n:d}\"],  \n",
    "                                    color=models[key].color,\n",
    "                                    alpha = 0.3 + 0.7*n/96)\n",
    "                \n",
    "            axes[n_fold-2, p].plot(peaks[peaks.n_peak == p][\"qmeas\"], color=\"gray\", #marker=\".\", \n",
    "                                           label=\"measured\")\n",
    "            axes[n_fold-2, p].plot(peaks[peaks.n_peak == p][\"qhyd\"],  color=\"b\", \n",
    "                                           label=\"PBHM\", ls=\"--\") \n",
    "\n",
    "            axes[n_fold-2, p].plot(peaks[peaks.n_peak == p][\"q0\"],  \n",
    "                                   color=models[key].color, ls=\"--\", \n",
    "                                   label=\"1st step prediction\")\n",
    "            axes[n_fold-2, p].plot(peaks[peaks.n_peak == p][\"q95\"],  \n",
    "                                   color=models[key].color, ls=\"-\", \n",
    "                                   label=\"96th step prediction\")\n",
    "            for n in range(0,96,1):\n",
    "                values  = peaks[peaks.n_peak == p][f\"q{n:d}\"]\n",
    "                axes[n_fold-2, p].plot(values.idxmax(), values.max(),\n",
    "                                    marker = \"x\",\n",
    "                                    color=\"k\",\n",
    "                                    alpha = 0.3 + 0.7*n/96)\n",
    "                \n",
    "            axes[n_fold-2, p].plot([],[],\n",
    "                                   marker= \"x\",\n",
    "                                   color = \"k\", ls=\"None\",\n",
    "                                   label = \"model peaks\")\n",
    "            axes[n_fold-2, p].set_xlim((dt_index[0],dt_index[-1]))\n",
    "            axes[n_fold-2, p].set_ylim(0,24)\n",
    "            \n",
    "            axes[n_fold-2, p].xaxis.set_minor_locator(mdates.MinuteLocator(byminute=range(0,60,60)))\n",
    "            \n",
    "            axes[n_fold-2, p].xaxis.set_major_locator(mdates.HourLocator(byhour=range(0,28,12)))\n",
    "            axes[n_fold-2, p].xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "            \n",
    "            axes[n_fold-2, p].yaxis.set_major_locator(FixedLocator(range(0,25,4)))\n",
    "            \n",
    "            axes[n_fold-2, p].set_xlabel(dt_index[96].strftime(\"%d.%m.%Y\"))\n",
    "            if p == 0:\n",
    "                label = [r\"$\\bf{\"+f\"fold\\ {2011 + n_fold}\"+r\"}$\", \"discharge ($m^3s^{-1}$)\"]\n",
    "                axes[n_fold-2, p].set_ylabel(\"\\n\".join(label))\n",
    "            elif p == 1:\n",
    "                axes2.set_ylabel(\"precipitation ($mm$)\")\n",
    "\n",
    "            if n_fold-2 == 0:\n",
    "                 axes[n_fold-2, p].set_title(f\"flood event {p+1}\")\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    axes[0,1].legend(bbox_to_anchor=(-0.25, 1.25), \n",
    "                 loc='lower center', ncol=3, \n",
    "                 borderaxespad=0)\n",
    "    plt.show()\n",
    "    plt.pause(0.001)\n",
    "    fig.savefig(os.path.join(PLOT_PATH, f'figX-peaks_{models[key].name}.png'), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f57ae-a7c8-47cd-8da1-d07fce392249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
